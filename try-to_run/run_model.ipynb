{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDh3cvElUlAN"
   },
   "outputs": [],
   "source": [
    "def create_model(model_name, n_points=0):\n",
    "\n",
    "        if model_name == \"SIGMOID_HEATMAP_SIGMOID_REGRESS_TWO_HEAD\":\n",
    "            return BlazePoseLegacy(n_points).build_model(\"TWO_HEAD\")\n",
    "        elif model_name == \"SIGMOID_HEATMAP_SIGMOID_REGRESS_HEATMAP\":\n",
    "            return BlazePoseLegacy(n_points).build_model(\"HEATMAP\")\n",
    "        elif model_name == \"SIGMOID_HEATMAP_SIGMOID_REGRESS_REGRESSION\":\n",
    "            return BlazePoseLegacy(n_points).build_model(\"REGRESSION\")\n",
    "\n",
    "        elif model_name == \"SIGMOID_HEATMAP_LINEAR_REGRESS_TWO_HEAD\":\n",
    "            return BlazePose(n_points).build_model(\"TWO_HEAD\")\n",
    "        elif model_name == \"SIGMOID_HEATMAP_LINEAR_REGRESS_HEATMAP\":\n",
    "            return BlazePose(n_points).build_model(\"HEATMAP\")\n",
    "        elif model_name == \"SIGMOID_HEATMAP_LINEAR_REGRESS_REGRESSION\":\n",
    "            return BlazePose(n_points).build_model(\"REGRESSION\")\n",
    "\n",
    "        elif model_name == \"ALL_LINEAR_TWO_HEAD\":\n",
    "            return BlazePoseAllLinear(n_points).build_model(\"TWO_HEAD\")\n",
    "        elif model_name == \"ALL_LINEAR_HEATMAP\":\n",
    "            return BlazePoseAllLinear(n_points).build_model(\"HEATMAP\")\n",
    "        elif model_name == \"ALL_LINEAR_REGRESSION\":\n",
    "            return BlazePoseAllLinear(n_points).build_model(\"REGRESSION\")\n",
    "\n",
    "        elif model_namModelCreator.e == \"PUSHUP_RECOGNITION\":\n",
    "            return PushUpRecognition.build_model()\n",
    "\n",
    "        elif model_name == \"BLAZEPOSE_WITH_PUSHUP_CLASSIFY\":\n",
    "            return BlazePoseWithClassify(n_points).build_model(\"TWO_HEAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POAyxeYxbSp7"
   },
   "outputs": [],
   "source": [
    "class ChannelPadding(tf.keras.layers.Layer):\n",
    "    def __init__(self, channels):\n",
    "        super(ChannelPadding, self).__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        self.pad_shape = tf.constant(\n",
    "            [[0, 0], [0, 0], [0, 0], [0, self.channels - input_shapes[-1]]])\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.pad(x, self.pad_shape)\n",
    "\n",
    "\n",
    "class BlazeBlock(tf.keras.Model):\n",
    "    def __init__(self, block_num=3, channel=48, channel_padding=1, name_prefix=\"\"):\n",
    "        super(BlazeBlock, self).__init__()\n",
    "\n",
    "        self.downsample_a = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(kernel_size=3, strides=(\n",
    "                2, 2), padding='same', activation=None, name=name_prefix+\"downsample_a_depthwise\"),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=channel, kernel_size=1, activation=None, name=name_prefix+\"downsample_a_conv1x1\")\n",
    "        ])\n",
    "        if channel_padding:\n",
    "            self.downsample_b = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "                ChannelPadding(channels=channel)\n",
    "            ])\n",
    "        else:\n",
    "            self.downsample_b = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "\n",
    "        self.conv = list()\n",
    "        for i in range(block_num):\n",
    "            self.conv.append(tf.keras.models.Sequential([\n",
    "                tf.keras.layers.DepthwiseConv2D(\n",
    "                    kernel_size=3, padding='same', activation=None, name=name_prefix+\"conv_block_{}\".format(i+1)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=channel, kernel_size=1, activation=None)\n",
    "            ]))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.keras.activations.relu(\n",
    "            self.downsample_a(x) + self.downsample_b(x))\n",
    "        for i in range(len(self.conv)):\n",
    "            x = tf.keras.activations.relu(x + self.conv[i](x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJz95xzqbiNq"
   },
   "outputs": [],
   "source": [
    "class BlazePose():\n",
    "    def __init__(self, num_keypoints: int):\n",
    "\n",
    "        self.num_keypoints = num_keypoints\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=24, kernel_size=3, strides=(2, 2), padding='same', activation='relu'\n",
    "        )\n",
    "\n",
    "        self.conv2_1 = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding='same', activation=None),\n",
    "            tf.keras.layers.Conv2D(filters=24, kernel_size=1, activation=None)\n",
    "        ])\n",
    "\n",
    "        self.conv2_2 = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding='same', activation=None),\n",
    "            tf.keras.layers.Conv2D(filters=24, kernel_size=1, activation=None)\n",
    "        ])\n",
    "\n",
    "        # === Heatmap ===\n",
    "\n",
    "        self.conv3 = BlazeBlock(block_num=3, channel=48)\n",
    "        self.conv4 = BlazeBlock(block_num=4, channel=96)\n",
    "        self.conv5 = BlazeBlock(block_num=5, channel=192)\n",
    "        self.conv6 = BlazeBlock(block_num=6, channel=288)\n",
    "\n",
    "        self.conv7a = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=48, kernel_size=1, activation=\"relu\"),\n",
    "            tf.keras.layers.UpSampling2D(size=(2, 2), interpolation=\"bilinear\")\n",
    "        ])\n",
    "        self.conv7b = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=48, kernel_size=1, activation=\"relu\")\n",
    "        ])\n",
    "\n",
    "        self.conv8a = tf.keras.layers.UpSampling2D(\n",
    "            size=(2, 2), interpolation=\"bilinear\")\n",
    "        self.conv8b = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=48, kernel_size=1, activation=\"relu\")\n",
    "        ])\n",
    "\n",
    "        self.conv9a = tf.keras.layers.UpSampling2D(\n",
    "            size=(2, 2), interpolation=\"bilinear\")\n",
    "        self.conv9b = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=48, kernel_size=1, activation=\"relu\")\n",
    "        ])\n",
    "\n",
    "        self.conv10a = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=8, kernel_size=1, activation=\"relu\"),\n",
    "            tf.keras.layers.UpSampling2D(size=(2, 2), interpolation=\"bilinear\")\n",
    "        ])\n",
    "        self.conv10b = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None),\n",
    "            tf.keras.layers.Conv2D(filters=8, kernel_size=1, activation=\"relu\")\n",
    "        ])\n",
    "\n",
    "        self.conv11 = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=8, kernel_size=1, activation=\"relu\"),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=self.num_keypoints, kernel_size=3, padding=\"same\", activation=None) # -> Heatmap output\n",
    "        ])\n",
    "\n",
    "        # === Regression ===\n",
    "\n",
    "        #  In: 1, 64, 64, 48)\n",
    "        self.conv12a = BlazeBlock(block_num=4, channel=96, name_prefix=\"regression_conv12a_\")    # input res: 64\n",
    "        self.conv12b = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None, name=\"regression_conv12b_depthwise\"),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=96, kernel_size=1, activation=\"relu\", name=\"regression_conv12b_conv1x1\")\n",
    "        ], name=\"regression_conv12b\")\n",
    "\n",
    "        self.conv13a = BlazeBlock(block_num=5, channel=192, name_prefix=\"regression_conv13a_\")   # input res: 32\n",
    "        self.conv13b = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None, name=\"regression_conv13b_depthwise\"),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=192, kernel_size=1, activation=\"relu\", name=\"regression_conv13b_conv1x1\")\n",
    "        ], name=\"regression_conv13b\")\n",
    "\n",
    "        self.conv14a = BlazeBlock(block_num=6, channel=288, name_prefix=\"regression_conv14a_\")   # input res: 16\n",
    "        self.conv14b = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size=3, padding=\"same\", activation=None, name=\"regression_conv14b_depthwise\"),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=288, kernel_size=1, activation=\"relu\", name=\"regression_conv14b_conv1x1\")\n",
    "        ], name=\"regression_conv14b\")\n",
    "\n",
    "        self.conv15 = tf.keras.models.Sequential([\n",
    "            BlazeBlock(block_num=7, channel=288, channel_padding=0, name_prefix=\"regression_conv15a_\"),\n",
    "            BlazeBlock(block_num=7, channel=288, channel_padding=0, name_prefix=\"regression_conv15b_\")\n",
    "        ], name=\"regression_conv15\")\n",
    "\n",
    "        self.conv16 = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=3*self.num_keypoints, kernel_size=2, activation=None),\n",
    "            tf.keras.layers.Reshape((3*self.num_keypoints, 1), name=\"regression_final_dense\")\n",
    "        ], name=\"joints\")\n",
    "\n",
    "    def build_model(self, model_type):\n",
    "\n",
    "        input_x = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "        # Block 1\n",
    "        # In: 1x256x256x3\n",
    "        x = self.conv1(input_x)\n",
    "\n",
    "        # Block 2\n",
    "        # In: 1x128x128x24\n",
    "        x = x + self.conv2_1(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        # Block 3\n",
    "        # In: 1x128x128x24\n",
    "        x = x + self.conv2_2(x)\n",
    "        y0 = tf.keras.activations.relu(x)\n",
    "\n",
    "        # === Heatmap ===\n",
    "\n",
    "        # In: 1, 128, 128, 24\n",
    "        y1 = self.conv3(y0)\n",
    "        y2 = self.conv4(y1)\n",
    "        y3 = self.conv5(y2)\n",
    "        y4 = self.conv6(y3)\n",
    "\n",
    "        x = self.conv7a(y4) + self.conv7b(y3)\n",
    "        x = self.conv8a(x) + self.conv8b(y2)\n",
    "        # In: 1, 32, 32, 96\n",
    "        x = self.conv9a(x) + self.conv9b(y1)\n",
    "        # In: 1, 64, 64, 48\n",
    "        y = self.conv10a(x) + self.conv10b(y0)\n",
    "        y = self.conv11(y)\n",
    "\n",
    "        # In: 1, 128, 128, 8\n",
    "        heatmap = tf.keras.layers.Activation(\"sigmoid\", name=\"heatmap\")(y)\n",
    "\n",
    "        # === Regression ===\n",
    "\n",
    "        # Stop gradient for regression on 2-head model\n",
    "        if model_type == \"TWO_HEAD\":\n",
    "            x = tf.keras.backend.stop_gradient(x)\n",
    "            y2 = tf.keras.backend.stop_gradient(y2)\n",
    "            y3 = tf.keras.backend.stop_gradient(y3)\n",
    "            y4 = tf.keras.backend.stop_gradient(y4)\n",
    "\n",
    "        x = self.conv12a(x) + self.conv12b(y2)\n",
    "        # In: 1, 32, 32, 96\n",
    "        x = self.conv13a(x) + self.conv13b(y3)\n",
    "        # In: 1, 16, 16, 192\n",
    "        x = self.conv14a(x) + self.conv14b(y4)\n",
    "        # In: 1, 8, 8, 288\n",
    "        x = self.conv15(x)\n",
    "        # In: 1, 2, 2, 288\n",
    "        joints = self.conv16(x)\n",
    "\n",
    "        if model_type == \"TWO_HEAD\":\n",
    "            return Model(inputs=input_x, outputs=[joints, heatmap])\n",
    "        elif model_type == \"HEATMAP\":\n",
    "            return Model(inputs=input_x, outputs=heatmap)\n",
    "        elif model_type == \"REGRESSION\":\n",
    "            return Model(inputs=input_x, outputs=joints)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong model type.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1635374118196,
     "user": {
      "displayName": "walaa salah",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04670010813509120725"
     },
     "user_tz": -120
    },
    "id": "u09qSPL18sKl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import json\n",
    "from tensorflow.keras.models import Model\n",
    "def set_env():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Restrict TensorFlow to only use the fourth GPU\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "def runnmodel(config, model_path):\n",
    "    \"\"\"Load pretrained model\n",
    "\n",
    "    Args:\n",
    "        config (dict): Model configuration\n",
    "        model (str): Path to h5 model to be tested\n",
    "    \"\"\"\n",
    "\n",
    "    model_config = config[\"model\"]\n",
    "\n",
    "    # Initialize model and load weights\n",
    "    model =create_model(model_config[\"model_type\"])\n",
    "    model.compile()\n",
    "    #model.load_weights(model_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#def return_model(filepath):\n",
    "\n",
    "  #  model = load_model(filepath)\n",
    "  #  model.compile()\n",
    "   # return model\n",
    "\n",
    "def get_preds(model , image):\n",
    "    img = np.expand_dims(image , axis = 0)\n",
    "    print(img )\n",
    "    preds = model.predict(img)\n",
    "    print(preds)\n",
    "    return preds\n",
    "\n",
    "def convert_preds_to_xy(preds):\n",
    "\n",
    "    kpts = []\n",
    "    #temp = preds[2][0]\n",
    "    temp = preds[1][0]\n",
    "    for x,y in zip(temp[::4] , temp[1::4]):\n",
    "        kpts.append(((x),(y)))\n",
    "        #kpts.append((int(x),int(y)))\n",
    "      \n",
    "    return kpts \n",
    "\n",
    "def infer_video(model , video = 0 ):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        okay , frame = cap.read()\n",
    "        if not okay :\n",
    "            print('Cant open webcam , please try again!')\n",
    "            break\n",
    "\n",
    "        \n",
    "        inframe = frame.copy()\n",
    "        inframe_resize = cv2.resize(inframe , (256 , 256)) / 255\n",
    "        \n",
    "        preds = get_preds(model , inframe_resize)\n",
    "        kpts = convert_preds_to_xy(preds)\n",
    "\n",
    "        for pair in POSE_PAIRS:\n",
    "            cv2.line(inframe_resize, kpts[pair[0]], kpts[pair[1]], (0, 255, 0), thickness=1)\n",
    "        # for point in kpts:\n",
    "        #     cv2.circle(inframe_resize , point , 2, (0,0,255) , 2)\n",
    "        cv2.imshow('Inference' , inframe_resize)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def infer_image(model , image):\n",
    "    img = cv2.imread(image)\n",
    "    img_resize = cv2.resize(img , (256 , 256)) / 255\n",
    "    preds = get_preds(model , img_resize)\n",
    "\n",
    "    kpts = convert_preds_to_xy(preds)\n",
    "    print(len(kpts))\n",
    "    for pair in POSE_PAIRS:\n",
    "        cv2.line(img_resize, kpts[pair[0]], kpts[pair[1]], (0, 255, 0), thickness=1)\n",
    "    #error: only size-1 arrays can be converted to Python scalars\n",
    "\n",
    "    # for idx , point in enumerate(kpts):\n",
    "    #     cv2.circle(img_resize , point, 2 , (0 , 0 , 255) , 2)\n",
    "    #     cv2.putText(img_resize, \"{}\".format(idx), point, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0 , 255 ,0), 1, lineType=cv2.LINE_AA)   \n",
    "        # cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), thickness=line_thickness)\n",
    "    cv2.imshow('Inference Image' , img_resize)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkSFwKq_-Ial"
   },
   "outputs": [],
   "source": [
    "POSE_PAIRS = [(11 ,12) , (12 ,14) ,(11,13) ,(13,15) ,(14,16) ,(0,11),(0,12)\n",
    "                ]\n",
    "set_env()\n",
    "\n",
    "with open('config.json') as config_buffer:\n",
    "    config = json.loads(config_buffer.read())\n",
    "    \n",
    "model = runnmodel(config,'path to h5 model')\n",
    "#model.summary()\n",
    "#infer_video(model)\n",
    "infer_image(model , 'image.jpg')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNOCIpc8Z9Vxh1xMCBHPrHk",
   "collapsed_sections": [],
   "mount_file_id": "1blx4u_r5KlUdsFoAuJISKCcnQu4aNtRo",
   "name": "run_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
